---------classification mode is cosine--------------------

Loading mini ImageNet dataset - phase train
Loading mini ImageNet dataset - phase val
Loading mini ImageNet dataset - phase test
/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 24.455 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 67.047 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 52.977 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 33.957 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 52.982 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 86.699 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 40.440 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 40.503 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 59.668 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 39.465 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 42.233 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 39.937 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 47.275 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 46.835 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 50.198 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 34.014 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 50.292 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 29.792 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 47.162 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 39.785 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 40.069 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 28.601 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 33.752 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 55.817 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 45.671 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 47.031 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 23.510 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 52.138 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 38.699 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 30.750 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 40.554 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 42.486 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 47.596 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 46.532 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 48.830 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 51.899 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 46.651 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 45.102 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 41.468 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 48.246 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 39.681 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 42.163 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 37.731 
5_shot_cosine_resent12_temp1000_dpout0.1_nowtmn======>[1/1000]  classification loss = 46.395 
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    final_model_state_dict,best_model_state_dict = trainer(model=model,device=device,train_loader=trainloader,val_loader=testloader,tester=tester,opts=args)
  File "/home/eegrad/snag/Desktop/fs_ood/src/train/new_trainer_bifurcate.py", line 97, in train
    emb_data,_,_,tau = model.encode(train_x)
  File "/home/eegrad/snag/Desktop/fs_ood/src/models/model.py", line 191, in encode
    z,mu,log_var,tau = self.enc_module(x)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/eegrad/snag/Desktop/fs_ood/src/models/model.py", line 60, in forward
    mu,log_var,tau = self.embed(x)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/eegrad/snag/Desktop/fs_ood/src/models/Resnet12.py", line 124, in forward
    sig = self.layer4_1(x) 
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/eegrad/snag/Desktop/fs_ood/src/models/Resnet12.py", line 55, in forward
    out = self.relu(out)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 756, in forward
    return F.leaky_relu(input, self.negative_slope, self.inplace)
  File "/home/eegrad/snag/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1474, in leaky_relu
    result = torch._C._nn.leaky_relu(input, negative_slope)
RuntimeError: CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 10.76 GiB total capacity; 8.79 GiB already allocated; 11.44 MiB free; 9.57 GiB reserved in total by PyTorch)
